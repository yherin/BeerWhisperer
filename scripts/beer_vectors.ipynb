{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe7e715a-9464-464c-98ed-58a0a5998dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import sklearn as skl\n",
    "import os\n",
    "import json\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import string\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stops = set(stopwords.words('english'))\n",
    "stops.add('notes')\n",
    "stops.add('note')\n",
    "stops.add('hint')\n",
    "stops.add('hints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9640cb6-890a-4a26-bd84-212e341abd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#first download the model from https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
    "# and extract the bin file. The download is VERY large, something like 9gb\n",
    "\n",
    "wmd = fasttext.load_model('../glove/wiki.en/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b132eb-17dc-4dfe-b048-8d7982b91c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x7fa2f070e760>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncomment this if you want to reduce the dimensions of the vectors, in principle larger vectors are more accurate. Default in the model is 300\n",
    "#fasttext.util.reduce_model(wmd, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b2297ac6-ac56-45fd-a51a-521e08eee2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index error for 904914\n",
      "index error for 902532\n",
      "index error for 921188\n"
     ]
    }
   ],
   "source": [
    "#load the beer data from the json\n",
    "beers = json.load(open('../data/beer_foods_tastes.json','r'))\n",
    "beer_taste_vectors = {}\n",
    "#for each beer, \n",
    "for b in beers.keys():\n",
    "    desc = beers[b]['taste_desc']\n",
    "    try:\n",
    "        #extract the colour, texture and taste words\n",
    "        col, feel, taste = partition_words(desc)\n",
    "        #prepare empty vector for addition\n",
    "        tasteVec = np.zeros(300)\n",
    "        for ta in taste:\n",
    "            #for each word in the taste description, fetch the word vector and sum them all together\n",
    "            tasteVec = np.add(tasteVec, wmd.get_word_vector(ta))\n",
    "        #store the summed vector representation in beer_taste_vectors dic \n",
    "        beer_taste_vectors[b] = tasteVec\n",
    "    except IndexError as e:\n",
    "        print(f'index error for {b}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b675e63-d5d3-4a4e-9577-ac6870373b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these functions are not used.\n",
    "#tried to write a function to guess whether a word belongs to taste or appearance or texture, but it was not accurate enough\n",
    "#def identify_token(token: str) -> str:\n",
    "#        label = measure_attributes(wmd.get_word_vector(token))\n",
    "#        if label is not None:\n",
    "#            return label\n",
    "#        else:\n",
    "#            raise ValueError(f'Labelling fail for {token} with label {label}')\n",
    "#    \n",
    "#def measure_attributes(v1: np.ndarray) -> tuple:\n",
    "#    scores = {}\n",
    "#    scores.clear()\n",
    "#    scores['appearance'] = distance(v1, vAppearance)\n",
    "#    scores['color'] = distance(v1, vColor)\n",
    "#    scores['taste'] = distance(v1, vTaste)\n",
    "#    scores['aroma'] = distance(v1, vAroma)\n",
    "#    scores['mouthfeel'] = distance(v1, vMouthFeel)\n",
    "#    scores['texture']  = distance(v1, vTexture)\n",
    "#    print(scores)\n",
    "#    return max(scores, key=scores.get)\n",
    "#    \n",
    "#\n",
    "#def distance(v1: np.ndarray, v2: np.ndarray) -> float: \n",
    "#    return (1 - spatial.distance.cosine(v1, v2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ebedaa70-2f79-4a23-b852-2fbf73181b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_beers(beer_id: str, n=25):\n",
    "    \n",
    "    ranking = {}\n",
    "    errors = 0\n",
    "    success = 0\n",
    "    groundVect = beer_taste_vectors[beer_id]\n",
    "    for b in beer_taste_vectors.keys():\n",
    "        try:\n",
    "            compareVect = beer_taste_vectors[b]\n",
    "            #print(compareVect.shape, groundVect.shape)\n",
    "            ranking[b] = ((1 - spatial.distance.cosine(groundVect, compareVect)))\n",
    "            success += 1\n",
    "        except ValueError as e:\n",
    "            #print(f'skipped processing for {b}')\n",
    "            #print(e)\n",
    "            errors += 1\n",
    "    print(f'{errors} errors')\n",
    "    print(f'{success} done')\n",
    "    sorted_list = sorted(ranking.items(), key=lambda item: item[1])\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list[:n]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f6056733-76af-4305-b3fc-2b9399d5147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_words(desc: str) -> tuple[str]:\n",
    "    #print(desc)\n",
    "    terms = process(desc).split(',')\n",
    "    #print(terms)\n",
    "    color = terms[0]\n",
    "    #print(color)\n",
    "    mouthfeel = terms[1]\n",
    "    #print(mouthfeel)\n",
    "    taste = terms[2:]\n",
    "    #print(taste)\n",
    "    return color, mouthfeel, taste\n",
    "\n",
    "def process(desc: str) -> str:\n",
    "    tempTerms = []\n",
    "    desc = desc.lower().strip()\n",
    "    mapping = desc.maketrans({'-': '_'})\n",
    "    desc = desc.translate(mapping)\n",
    "    for terms in desc.split(','):\n",
    "        #print(terms)\n",
    "        term = ' '.join([ t for t in terms.split() if (t not in stops)])\n",
    "        #print(term)\n",
    "        tempTerms.append(term)\n",
    "    #print(tempTerms)\n",
    "    return ','.join(tempTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "206666f7-dd36-4021-b828-a6eb528008cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors\n",
      "1153 done\n",
      "918895\t1\n",
      "914782\t1\n",
      "924208\t0.9261185413166917\n",
      "951272\t0.9250384829635898\n",
      "906362\t0.9250384829635898\n",
      "944094\t0.9250384829635898\n",
      "933365\t0.9187346696817323\n",
      "945748\t0.9187346696817323\n",
      "958154\t0.9170359218713465\n",
      "959684\t0.9081323325230717\n",
      "915645\t0.9081323325230717\n",
      "958438\t0.9029874894647677\n",
      "945454\t0.894810640220399\n",
      "936093\t0.8907280581646628\n",
      "946598\t0.8880899557958529\n",
      "904124\t0.8880899557958529\n",
      "911982\t0.8837754604299842\n",
      "910643\t0.8837754604299842\n",
      "923116\t0.8837754604299842\n",
      "956468\t0.8837754604299842\n",
      "953912\t0.8837754604299842\n",
      "905853\t0.8837754604299842\n",
      "912546\t0.8827788698677748\n",
      "933304\t0.8827463540904674\n",
      "923204\t0.8827463540904674\n"
     ]
    }
   ],
   "source": [
    "closest = nearest_beers('914782', n=25)\n",
    "for i in closest:\n",
    "    print(i[0], i[1], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "21214847-841a-489e-a4f3-27087e74c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.26931648301252\n",
      "33.901781855939504\n",
      "80.08023513648725\n"
     ]
    }
   ],
   "source": [
    "print(spatial.distance.euclidean(wmd.get_word_vector('finland'), wmd.get_word_vector('spain')) **3)\n",
    "print(spatial.distance.euclidean(wmd.get_word_vector('finland'), wmd.get_word_vector('sweden')) **3)\n",
    "print(spatial.distance.euclidean(wmd.get_word_vector('spain'), wmd.get_word_vector('sweden')) **3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f16dd6-f070-44ef-af4f-ca07c370b046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
